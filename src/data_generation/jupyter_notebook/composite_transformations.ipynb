{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composite Transformations\n",
    "\n",
    "In this notebook we will explore how to do a composition of transformations which will reflect our synthetic data pipeline. \n",
    "\n",
    "We will investigate:\n",
    "- How to rotate our bounding box coordinates along with the image\n",
    "    - Recall we are using the YOLO ml algorithm for our model. \n",
    "    - So if we rotate the image we will need to perserve the coordinates for the classification i.e. the top left corner of the card that holds the value and suit\n",
    "    - we need to also perserve the coordinates for the card outline. These coordinates will not be labels for the training set but they are needed to construct a masking for the background changes\n",
    "- How the transformations differ when we apply them in different order\n",
    "    -  For e.g. we know that: blur -> contrast -> noise =/= contrast -> noise ->  blur "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate corner bounding box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "img_path = \"../../../data/raw/as.jpg\" # path to image \n",
    "path = os.path.abspath(img_path)\n",
    "img = cv2.imread(path) # load image\n",
    "\n",
    "h, w = img.shape[:2] \n",
    "class_id, x_cent, y_cent, box_w, box_h = 9, 0.2671875, 0.1625, 0.059375, 0.09765625  # Classificaiton label i.e. Top-left corner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original image with the bounding box highlighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: 9 0.2671875 0.1625 0.059375 0.09765625\n"
     ]
    }
   ],
   "source": [
    "# Convert to pixels for drawing\n",
    "x_min = int((x_cent - box_w / 2) * w)  # ~97\n",
    "x_max = int((x_cent + box_w / 2) * w)  # ~388\n",
    "y_min = int((y_cent - box_h / 2) * h)  # ~103\n",
    "y_max = int((y_cent + box_h / 2) * h)  # ~412\n",
    "\n",
    "# Draw lines connecting corners (rectangle)\n",
    "cv2.line(img, (x_min, y_min), (x_max, y_min), (0, 255, 0), 2)  # Top\n",
    "cv2.line(img, (x_max, y_min), (x_max, y_max), (0, 255, 0), 2)  # Right\n",
    "cv2.line(img, (x_max, y_max), (x_min, y_max), (0, 255, 0), 2)  # Bottom\n",
    "cv2.line(img, (x_min, y_max), (x_min, y_min), (0, 255, 0), 2)  # Left\n",
    "\n",
    "# Save\n",
    "cv2.imwrite(\"original_with_box.jpg\", img)\n",
    "print(f\"Original label: {class_id} {x_cent} {y_cent} {box_w} {box_h}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rotated image with the rotated bounding box highlighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../../../data/raw/as.jpg\" # path to image \n",
    "path = os.path.abspath(img_path)\n",
    "img = cv2.imread(path) # load image\n",
    "\n",
    "h, w = img.shape[:2]  # 2061, 1940\n",
    "class_id, x_cent, y_cent, box_w, box_h = 6, 0.2671875, 0.1625, 0.059375, 0.09765625  # Classificaiton label i.e. Top-left corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New label: 6 0.15060178436322855 0.3405530033846654 0.059375 0.09765625\n"
     ]
    }
   ],
   "source": [
    "# Rotation\n",
    "theta = 30  # Degrees, adjust as needed\n",
    "center = (w // 2, h // 2)  # Rotate around image center\n",
    "M = cv2.getRotationMatrix2D(center, theta, 1.0)\n",
    "rotated_img = cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "# Rotate classification box center\n",
    "x_cent_px = x_cent * w\n",
    "y_cent_px = y_cent * h\n",
    "center_point = np.array([x_cent_px, y_cent_px, 1])  # Homogeneous coords\n",
    "new_center = M.dot(center_point)\n",
    "new_x_cent = new_center[0] / w  # Normalize back\n",
    "new_y_cent = new_center[1] / h\n",
    "\n",
    "# Width/height stay the same (upright box approximation)\n",
    "new_box_w, new_box_h = box_w, box_h\n",
    "new_label = f\"{class_id} {new_x_cent} {new_y_cent} {new_box_w} {new_box_h}\"\n",
    "\n",
    "# Convert to pixels for drawing\n",
    "x_min = int((new_x_cent - new_box_w / 2) * w)\n",
    "x_max = int((new_x_cent + new_box_w / 2) * w)\n",
    "y_min = int((new_y_cent - new_box_h / 2) * h)\n",
    "y_max = int((new_y_cent + new_box_h / 2) * h)\n",
    "\n",
    "# Draw lines connecting corners (rectangle)\n",
    "cv2.line(rotated_img, (x_min, y_min), (x_max, y_min), (0, 255, 0), 2)  # Top\n",
    "cv2.line(rotated_img, (x_max, y_min), (x_max, y_max), (0, 255, 0), 2)  # Right\n",
    "cv2.line(rotated_img, (x_max, y_max), (x_min, y_max), (0, 255, 0), 2)  # Bottom\n",
    "cv2.line(rotated_img, (x_min, y_max), (x_min, y_min), (0, 255, 0), 2)  # Left\n",
    "\n",
    "# Save\n",
    "cv2.imwrite(\"rotated_with_box.jpg\", rotated_img)\n",
    "print(f\"New label: {new_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate outline bounding box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image and background\n",
    "img = cv2.imread(\"../../../data/raw/as.jpg\")\n",
    "bg = cv2.imread(\"../backgrounds/bg.jpg\")  # Replace with your bg file\n",
    "if img is None: raise Exception(\"Image not found\")\n",
    "if bg is None: raise Exception(\"Background not found\")\n",
    "\n",
    "h, w = img.shape[:2]  \n",
    "\n",
    "# Original bounding box (card outline for masking)\n",
    "class_id, x_cent, y_cent, box_w, box_h = 0, 0.471875, 0.496875, 0.490625, 0.78828125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rotate the image and bounding box coordinate with a theta value. Use that theta and the transformed coordinates to make a rotated mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: -25.676350864411962\n"
     ]
    }
   ],
   "source": [
    "theta = np.random.uniform(-30, 30)\n",
    "center = (w // 2, h // 2)\n",
    "M = cv2.getRotationMatrix2D(center, theta, 1.0)\n",
    "\n",
    "# Rotate image\n",
    "rotated_img = cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "# Create mask with original coords (before rotation)\n",
    "orig_x_min = int((x_cent - box_w / 2) * w)  # ~434\n",
    "orig_x_max = int((x_cent + box_w / 2) * w)  # ~1412\n",
    "orig_y_min = int((y_cent - box_h / 2) * h)  # ~210\n",
    "orig_y_max = int((y_cent + box_h / 2) * h)\n",
    "mask = np.zeros_like(img, dtype=np.uint8)\n",
    "mask[orig_y_min:orig_y_max, orig_x_min:orig_x_max] = 255\n",
    "\n",
    "# Rotate mask with theta\n",
    "rotated_mask = cv2.warpAffine(mask, M, (w, h))\n",
    "\n",
    "# Background swap (single photo)\n",
    "bg = cv2.resize(bg, (w, h))\n",
    "result = np.where(rotated_mask == 255, rotated_img, bg)\n",
    "\n",
    "# Save\n",
    "cv2.imwrite(\"rotated_masked_card.jpg\", result)\n",
    "print(f\"Theta: {theta}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
